{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15c3b849",
   "metadata": {},
   "source": [
    "# Step 1: v4 í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ë° ë°ì´í„° ìƒì„±\n",
    "\n",
    "## ğŸ“Œ ëª©ì \n",
    "ì´ ë…¸íŠ¸ë¶ì€ v1 ì „ì²˜ë¦¬ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ v4 í”¼ì²˜ë¥¼ ìƒì„±í•˜ê³ , í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ğŸ”„ í”„ë¡œì„¸ìŠ¤\n",
    "1. **v1 ë°ì´í„° ë¡œë“œ**: ê¸°ë³¸ ì „ì²˜ë¦¬ê°€ ì™„ë£Œëœ train/test ë°ì´í„°\n",
    "2. **v3.5 í”¼ì²˜ ìƒì„±**: Hybrid Top150 + ë„ë©”ì¸ íŒŒìƒë³€ìˆ˜ 6ê°œ\n",
    "3. **v4 ì‹ ê·œ í”¼ì²˜ ì¶”ê°€**: í¬ê·€ ì„¸ê·¸ë¨¼íŠ¸ íŠ¹í™” 15ê°œ í”¼ì²˜\n",
    "4. **ìµœì¢… ë°ì´í„° ì €ì¥**: 167ê°œ í”¼ì²˜ í¬í•¨ parquet íŒŒì¼\n",
    "\n",
    "## ğŸ“Š ì¶œë ¥ë¬¼\n",
    "- `data/df_master_v4_train.parquet`: í•™ìŠµ ë°ì´í„° (Segment í¬í•¨)\n",
    "- `data/df_master_v4_test.parquet`: í…ŒìŠ¤íŠ¸ ë°ì´í„° (Segment ì—†ìŒ)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c531a26e",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ ì½”ë“œ ì‹¤í–‰\n",
    "\n",
    "ì•„ë˜ ì…€ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ë©´ v4 í”¼ì²˜ê°€ ìƒì„±ë©ë‹ˆë‹¤.\n",
    "\n",
    "### ì£¼ìš” í•¨ìˆ˜ ì„¤ëª…\n",
    "- `yyyymmdd_to_datetime()`: ë‚ ì§œ ë³€í™˜ í•¨ìˆ˜\n",
    "- `add_v35_features()`: v3.5 í”¼ì²˜ ìƒì„± (Top150 + ë„ë©”ì¸ 6ê°œ)\n",
    "- `add_v4_features()`: v4 ì‹ ê·œ í”¼ì²˜ 15ê°œ ìƒì„±\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5969cc5c-82bc-457d-b0fd-a47521801544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW_PROJECT_ROOT : C:\\Users\\User\\ì „ì‚°í†µê³„í”„ë¡œì íŠ¸\n",
      "DATA_DIR_NEW     : C:\\Users\\User\\ì „ì‚°í†µê³„í”„ë¡œì íŠ¸\\data\n",
      "OLD_PROJECT_ROOT : C:\\Users\\User\\credit_segmentation-v4\n",
      "FEAT_DIR_OLD     : C:\\Users\\User\\credit_segmentation-v4\\features\n",
      "\n",
      "[Loaded v1 train] (400000, 851)\n",
      "[Loaded v1 test ] (100000, 850)\n",
      "\n",
      "=== v3.5 + v4 FE (train) ===\n",
      "Loaded top150_final: (150, 4)\n",
      "[Hybrid Top150 Feature ê°œìˆ˜]: 150\n",
      "\n",
      "[v3.5 ì»¤ìŠ¤í…€ íŒŒìƒë³€ìˆ˜ 6ê°œ]: ['v3_offline_ratio_R3M', 'v3_big_spend_ratio_R12M', 'v3_bill_change_R3M_R6M', 'v3_bill_mean_B5_B2_B0', 'v3_bill_change_B0_B5', 'v3_credit_intensity']\n",
      "[v3.5 ìµœì¢… Feature ê°œìˆ˜]: 156\n",
      "\n",
      "[v3.5] dfì— ì—†ëŠ” feature ìˆ˜: 0\n",
      "âœ… v3.5 feature ì „ë¶€ dfì— ì¡´ì¬\n",
      "[train_v4 shape]: (400000, 872)\n",
      "\n",
      "=== v3.5 + v4 FE (test) ===\n",
      "Loaded top150_final: (150, 4)\n",
      "[Hybrid Top150 Feature ê°œìˆ˜]: 150\n",
      "\n",
      "[v3.5 ì»¤ìŠ¤í…€ íŒŒìƒë³€ìˆ˜ 6ê°œ]: ['v3_offline_ratio_R3M', 'v3_big_spend_ratio_R12M', 'v3_bill_change_R3M_R6M', 'v3_bill_mean_B5_B2_B0', 'v3_bill_change_B0_B5', 'v3_credit_intensity']\n",
      "[v3.5 ìµœì¢… Feature ê°œìˆ˜]: 156\n",
      "\n",
      "[v3.5] dfì— ì—†ëŠ” feature ìˆ˜: 0\n",
      "âœ… v3.5 feature ì „ë¶€ dfì— ì¡´ì¬\n",
      "[test_v4 shape]: (100000, 871)\n",
      "\n",
      "[v4_feature_list ê°œìˆ˜]: 165\n",
      "\n",
      "[train] ìµœì¢… ì‚¬ìš© feature ìˆ˜: 165 (+Segment)\n",
      "[train] v4_list ê¸°ì¤€ ëˆ„ë½ feature ìˆ˜: 0\n",
      "[df_master_v4_train shape]: (400000, 166)\n",
      "\n",
      "[test] ìµœì¢… ì‚¬ìš© feature ìˆ˜: 165\n",
      "[test] v4_list ê¸°ì¤€ ëˆ„ë½ feature ìˆ˜: 0\n",
      "[df_master_v4_test shape]: (100000, 165)\n",
      "\n",
      "âœ… Saved v4:\n",
      " - C:\\Users\\User\\ì „ì‚°í†µê³„í”„ë¡œì íŠ¸\\data\\df_master_v4_train.parquet\n",
      " - C:\\Users\\User\\ì „ì‚°í†µê³„í”„ë¡œì íŠ¸\\data\\df_master_v4_test.parquet\n"
     ]
    }
   ],
   "source": [
    "# step1_build_v4_features_train_test.py\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --------------------------------\n",
    "# 0) ê²½ë¡œ ì„¤ì •\n",
    "# --------------------------------\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸: final_submission ê¸°ì¤€\n",
    "PROJECT_ROOT = Path(r\"C:\\Users\\User\\ì „ì‚°í†µê³„í”„ë¡œì íŠ¸\\final_submission\")\n",
    "DATA_DIR     = PROJECT_ROOT / \"data\"\n",
    "FEAT_DIR     = DATA_DIR / \"features\"\n",
    "\n",
    "# ì›ë³¸ ë°ì´í„° ê²½ë¡œ (v1 ì „ì²˜ë¦¬ ë°ì´í„° ìœ„ì¹˜)\n",
    "ORIGINAL_DATA_DIR = Path(r\"C:\\Users\\User\\ì „ì‚°í†µê³„í”„ë¡œì íŠ¸\\data\")\n",
    "\n",
    "print(\"PROJECT_ROOT :\", PROJECT_ROOT)\n",
    "print(\"DATA_DIR     :\", DATA_DIR)\n",
    "print(\"FEAT_DIR     :\", FEAT_DIR)\n",
    "print(\"ORIGINAL_DATA_DIR :\", ORIGINAL_DATA_DIR)\n",
    "\n",
    "EPS   = 1e-6\n",
    "TODAY = pd.Timestamp(\"2024-12-31\")   # ê¸°ì¤€ì¼ (ì˜ˆì „ ì½”ë“œì™€ ë™ì¼)\n",
    "\n",
    "# --------------------------------\n",
    "# 1) v3.5 / v4 FE í•¨ìˆ˜ ì •ì˜\n",
    "#    (ì˜ˆì „ì— ì“°ë˜ add_v35_features, add_v4_features ê·¸ëŒ€ë¡œ)\n",
    "# --------------------------------\n",
    "\n",
    "def yyyymmdd_to_datetime(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    YYYYMMDD í˜•íƒœ ìˆ«ì/ë¬¸ì ì‹œë¦¬ì¦ˆë¥¼ datetimeìœ¼ë¡œ ë³€í™˜.\n",
    "    ì˜ëª»ëœ ê°’ì€ NaT ì²˜ë¦¬.\n",
    "    \"\"\"\n",
    "    s_num = pd.to_numeric(s, errors=\"coerce\").astype(\"Int64\")\n",
    "    return pd.to_datetime(s_num, format=\"%Y%m%d\", errors=\"coerce\")\n",
    "\n",
    "\n",
    "def add_v35_features(df: pd.DataFrame, feat_dir: Path) -> tuple[pd.DataFrame, list]:\n",
    "    \"\"\"\n",
    "    v3.5 Hybrid Top150 + ë„ë©”ì¸ FE 6ê°œë¥¼ dfì— ì¶”ê°€í•˜ê³ ,\n",
    "    ìµœì¢… v3.5 feature ì´ë¦„ ë¦¬ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ë¦¬í„´.\n",
    "    \"\"\"\n",
    "    df_fe = df.copy()\n",
    "\n",
    "    # 1) Hybrid Top150 ë¡œë“œ\n",
    "    top150_path = feat_dir / \"top150_final.parquet\"\n",
    "    top150_final = pd.read_parquet(top150_path)\n",
    "\n",
    "    base_feats_150 = top150_final[\"feature\"].tolist()\n",
    "    print(\"Loaded top150_final:\", top150_final.shape)\n",
    "    print(\"[Hybrid Top150 Feature ê°œìˆ˜]:\", len(base_feats_150))\n",
    "\n",
    "    # 2) v3.5 ë„ë©”ì¸ FE 6ê°œ ìƒì„±\n",
    "    # (1) ìµœê·¼ 3ê°œì›” ì˜¤í”„ë¼ì¸ ë¹„ìœ¨\n",
    "    df_fe[\"v3_offline_ratio_R3M\"] = df_fe[\"ì´ìš©ê¸ˆì•¡_ì˜¤í”„ë¼ì¸_R3M\"] / (\n",
    "        df_fe[\"ì´ìš©ê¸ˆì•¡_ì˜¤í”„ë¼ì¸_R3M\"] + df_fe[\"ì´ìš©ê¸ˆì•¡_R3M_ì‹ ìš©ì²´í¬\"] + EPS\n",
    "    )\n",
    "\n",
    "    # (2) 12M ì¼ì‹œë¶ˆ ì¤‘ ê³ ì•¡ í•œ ê±´ ë¹„ìœ¨\n",
    "    df_fe[\"v3_big_spend_ratio_R12M\"] = df_fe[\"ìµœëŒ€ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_R12M\"] / (\n",
    "        df_fe[\"ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_R12M\"] + EPS\n",
    "    )\n",
    "\n",
    "    # (3) ì²­êµ¬ê¸ˆì•¡ R3M vs R6M ë³€í™”ìœ¨\n",
    "    df_fe[\"v3_bill_change_R3M_R6M\"] = (\n",
    "        df_fe[\"ì²­êµ¬ê¸ˆì•¡_R3M\"] - df_fe[\"ì²­êµ¬ê¸ˆì•¡_R6M\"]\n",
    "    ) / (df_fe[\"ì²­êµ¬ê¸ˆì•¡_R6M\"] + EPS)\n",
    "\n",
    "    # (4) B5/B2/B0 í‰ê·  ì²­êµ¬ê¸ˆì•¡\n",
    "    df_fe[\"v3_bill_mean_B5_B2_B0\"] = df_fe[\n",
    "        [\"ì •ìƒì²­êµ¬ì›ê¸ˆ_B5M\", \"ì •ìƒì²­êµ¬ì›ê¸ˆ_B2M\", \"ì •ìƒì²­êµ¬ì›ê¸ˆ_B0M\"]\n",
    "    ].mean(axis=1)\n",
    "\n",
    "    # (5) B5 ëŒ€ë¹„ B0 ì²­êµ¬ê¸ˆì•¡ ë³€í™”ìœ¨\n",
    "    df_fe[\"v3_bill_change_B0_B5\"] = (\n",
    "        df_fe[\"ì •ìƒì²­êµ¬ì›ê¸ˆ_B0M\"] - df_fe[\"ì •ìƒì²­êµ¬ì›ê¸ˆ_B5M\"]\n",
    "    ) / (df_fe[\"ì •ìƒì²­êµ¬ì›ê¸ˆ_B5M\"] + EPS)\n",
    "\n",
    "    # (6) ì‹ ìš© ì´ìš© ê°•ë„ (ì´ìš©ê¸ˆì•¡ëŒ€ Ã— log(1+ì‹ ìš©ê±´ìˆ˜))\n",
    "    credit_cnt = df_fe[\"ì´ìš©ê±´ìˆ˜_ì‹ ìš©_R12M\"].clip(lower=0)\n",
    "    df_fe[\"v3_credit_intensity\"] = df_fe[\"ì´ìš©ê¸ˆì•¡ëŒ€\"] * np.log1p(credit_cnt)\n",
    "\n",
    "    feats_v35_custom = [\n",
    "        \"v3_offline_ratio_R3M\",\n",
    "        \"v3_big_spend_ratio_R12M\",\n",
    "        \"v3_bill_change_R3M_R6M\",\n",
    "        \"v3_bill_mean_B5_B2_B0\",\n",
    "        \"v3_bill_change_B0_B5\",\n",
    "        \"v3_credit_intensity\",\n",
    "    ]\n",
    "\n",
    "    # ìµœì¢… v3.5 feature ë¦¬ìŠ¤íŠ¸\n",
    "    v35_features = base_feats_150 + feats_v35_custom\n",
    "    v35_features = list(dict.fromkeys(v35_features))  # ì¤‘ë³µ ì œê±° + ìˆœì„œ ìœ ì§€\n",
    "\n",
    "    print(\"\\n[v3.5 ì»¤ìŠ¤í…€ íŒŒìƒë³€ìˆ˜ 6ê°œ]:\", feats_v35_custom)\n",
    "    print(\"[v3.5 ìµœì¢… Feature ê°œìˆ˜]:\", len(v35_features))\n",
    "\n",
    "    # ì‹¤ì œ df ì•ˆì— ì—†ëŠ” ì»¬ëŸ¼ ì²´í¬ (ì•ˆì „ì¥ì¹˜)\n",
    "    missing_cols = [c for c in v35_features if c not in df_fe.columns]\n",
    "    print(\"\\n[v3.5] dfì— ì—†ëŠ” feature ìˆ˜:\", len(missing_cols))\n",
    "    if missing_cols:\n",
    "        print(\"ëˆ„ë½ ì»¬ëŸ¼ ì˜ˆì‹œ:\", missing_cols[:20])\n",
    "    else:\n",
    "        print(\"âœ… v3.5 feature ì „ë¶€ dfì— ì¡´ì¬\")\n",
    "\n",
    "    return df_fe, v35_features\n",
    "\n",
    "\n",
    "def add_v4_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    v3.5ê¹Œì§€ FEê°€ ë“¤ì–´ìˆëŠ” dfì—\n",
    "    v4 í¬ê·€ ì„¸ê·¸ ì „ìš© íŒŒìƒë³€ìˆ˜ë¥¼ ì¶”ê°€í•´ì„œ ë¦¬í„´.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # =============================\n",
    "    # 1) ë‚ ì§œ ì»¬ëŸ¼ datetime ë³€í™˜\n",
    "    # =============================\n",
    "    date_cols = [\n",
    "        \"ìµœì¢…ì´ìš©ì¼ì_CA\",\n",
    "        \"ìµœì¢…ì´ìš©ì¼ì_ì¼ì‹œë¶ˆ\",\n",
    "        \"ìµœì¢…ì´ìš©ì¼ì_ì‹ íŒ\",\n",
    "        \"ìµœì¢…ì´ìš©ì¼ì_í• ë¶€\",\n",
    "        \"ìµœì¢…ì´ìš©ì¼ì_ê¸°ë³¸\",\n",
    "        \"ìµœì¢…ì´ìš©ì¼ì_ì¹´ë“œë¡ \",\n",
    "    ]\n",
    "\n",
    "    for col in date_cols:\n",
    "        if col in df.columns:\n",
    "            df[col + \"_dt\"] = yyyymmdd_to_datetime(df[col])\n",
    "        else:\n",
    "            df[col + \"_dt\"] = pd.NaT  # ì—†ìœ¼ë©´ NaT\n",
    "\n",
    "    # â‘  v4_last_use_gap_CA\n",
    "    df[\"v4_last_use_gap_CA\"] = (TODAY - df[\"ìµœì¢…ì´ìš©ì¼ì_CA_dt\"]).dt.days\n",
    "\n",
    "    # â‘¡ v4_last_use_gap_card_all\n",
    "    last_use_all = df[[\n",
    "        \"ìµœì¢…ì´ìš©ì¼ì_ì¼ì‹œë¶ˆ_dt\",\n",
    "        \"ìµœì¢…ì´ìš©ì¼ì_ì‹ íŒ_dt\",\n",
    "        \"ìµœì¢…ì´ìš©ì¼ì_í• ë¶€_dt\",\n",
    "        \"ìµœì¢…ì´ìš©ì¼ì_ê¸°ë³¸_dt\",\n",
    "    ]].max(axis=1)\n",
    "    df[\"v4_last_use_gap_card_all\"] = (TODAY - last_use_all).dt.days\n",
    "\n",
    "    # â‘¢ v4_first_to_last_gap (ê°€ì… ~ ìµœì¢… ì´ìš©ê¹Œì§€ ê¸°ê°„)\n",
    "    if \"rvìµœì´ˆì‹œì‘í›„ê²½ê³¼ì¼\" in df.columns:\n",
    "        rv_days = pd.to_numeric(df[\"rvìµœì´ˆì‹œì‘í›„ê²½ê³¼ì¼\"], errors=\"coerce\")\n",
    "\n",
    "        max_reasonable_days = 365 * 200\n",
    "        rv_days = rv_days.mask(rv_days > max_reasonable_days, np.nan)\n",
    "\n",
    "        rv_delta = pd.to_timedelta(rv_days, unit=\"D\")\n",
    "        join_date = TODAY - rv_delta\n",
    "\n",
    "        df[\"v4_first_to_last_gap\"] = (\n",
    "            df[\"ìµœì¢…ì´ìš©ì¼ì_ê¸°ë³¸_dt\"] - join_date\n",
    "        ).dt.days\n",
    "    else:\n",
    "        df[\"v4_first_to_last_gap\"] = np.nan\n",
    "\n",
    "    # â‘£ v4_limit_to_usage_ratio_R12M\n",
    "    num_12m = (\n",
    "        df.get(\"ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_R12M\", 0)\n",
    "        + df.get(\"ì´ìš©ê¸ˆì•¡_í• ë¶€_R12M\", 0)\n",
    "        + df.get(\"ì´ìš©ê¸ˆì•¡_CA_R12M\", 0)\n",
    "    )\n",
    "    limit_amt = df.get(\"ì¹´ë“œì´ìš©í•œë„ê¸ˆì•¡\", 0)\n",
    "    df[\"v4_limit_to_usage_ratio_R12M\"] = num_12m / (limit_amt + EPS)\n",
    "\n",
    "    # â‘¤ v4_balance_to_usage_ratio\n",
    "    num_bal = df.get(\"í‰ì”_6M\", 0)\n",
    "    den_use_6m = (\n",
    "        df.get(\"ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_R6M\", 0)\n",
    "        + df.get(\"ì´ìš©ê¸ˆì•¡_í• ë¶€_R6M\", 0)\n",
    "        + df.get(\"ì´ìš©ê¸ˆì•¡_CA_R6M\", 0)\n",
    "        + EPS\n",
    "    )\n",
    "    df[\"v4_balance_to_usage_ratio\"] = num_bal / den_use_6m\n",
    "\n",
    "    # â‘¥ v4_bill_drop_R6_to_R3\n",
    "    bill_6 = df.get(\"ì²­êµ¬ê¸ˆì•¡_R6M\", 0)\n",
    "    bill_3 = df.get(\"ì²­êµ¬ê¸ˆì•¡_R3M\", 0)\n",
    "    df[\"v4_bill_drop_R6_to_R3\"] = (bill_6 - bill_3) / (bill_6 + EPS)\n",
    "\n",
    "    # â‘¦ v4_usage_volatility_R3_R6_R12\n",
    "    use_matrix = pd.concat(\n",
    "        [\n",
    "            df.get(\"ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_R3M\",  pd.Series(0, index=df.index)),\n",
    "            df.get(\"ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_R6M\",  pd.Series(0, index=df.index)),\n",
    "            df.get(\"ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_R12M\", pd.Series(0, index=df.index)),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    df[\"v4_usage_volatility_R3_R6_R12\"] = use_matrix.std(axis=1)\n",
    "\n",
    "    # â‘§ v4_recent_zero_usage_flag\n",
    "    recent_3m_sum = (\n",
    "        df.get(\"ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_R3M\", 0)\n",
    "        + df.get(\"ì´ìš©ê¸ˆì•¡_í• ë¶€_R3M\", 0)\n",
    "        + df.get(\"ì´ìš©ê¸ˆì•¡_CA_R3M\", 0)\n",
    "    )\n",
    "    df[\"v4_recent_zero_usage_flag\"] = (recent_3m_sum == 0).astype(\"int8\")\n",
    "\n",
    "    # â‘¨ v4_long_inactive_high_limit_flag\n",
    "    use_12m = (\n",
    "        df.get(\"ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_R12M\", 0).fillna(0) +\n",
    "        df.get(\"ì´ìš©ê¸ˆì•¡_í• ë¶€_R12M\", 0).fillna(0) +\n",
    "        df.get(\"ì´ìš©ê¸ˆì•¡_CA_R12M\", 0).fillna(0)\n",
    "    )\n",
    "    last_basic_gap = (TODAY - df[\"ìµœì¢…ì´ìš©ì¼ì_ê¸°ë³¸_dt\"]).dt.days\n",
    "\n",
    "    cond_high_limit    = df.get(\"ì¹´ë“œì´ìš©í•œë„ê¸ˆì•¡\", 0) > 3_000_000\n",
    "    cond_low_usage     = use_12m < 100_000\n",
    "    cond_long_inactive = last_basic_gap > 365\n",
    "\n",
    "    df[\"v4_long_inactive_high_limit_flag\"] = (\n",
    "        cond_high_limit & cond_low_usage & cond_long_inactive\n",
    "    ).astype(\"int8\")\n",
    "\n",
    "    # â‘© v4_point_activity_intensity\n",
    "    point_sum = (\n",
    "        df.get(\"í¬ì¸íŠ¸_ì ë¦½í¬ì¸íŠ¸_R12M\", 0)\n",
    "        + df.get(\"í¬ì¸íŠ¸_ì´ìš©í¬ì¸íŠ¸_R12M\", 0)\n",
    "    )\n",
    "    spend_12m = (\n",
    "        df.get(\"ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_R12M\", 0)\n",
    "        + df.get(\"ì´ìš©ê¸ˆì•¡_í• ë¶€_R12M\", 0)\n",
    "        + EPS\n",
    "    )\n",
    "    df[\"v4_point_activity_intensity\"] = point_sum / spend_12m\n",
    "\n",
    "    # â‘ª v4_travel_mileage_activity\n",
    "    mileage_sum = (\n",
    "        df.get(\"ë§ˆì¼_ì ë¦½í¬ì¸íŠ¸_R12M\", 0)\n",
    "        + df.get(\"ë§ˆì¼_ì´ìš©í¬ì¸íŠ¸_R12M\", 0)\n",
    "    )\n",
    "    spend_12m_only = df.get(\"ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_R12M\", 0) + EPS\n",
    "    df[\"v4_travel_mileage_activity\"] = mileage_sum / spend_12m_only\n",
    "\n",
    "    # â‘« v4_lifestyle_auto_payment_flag\n",
    "    comm = df.get(\"ë‚©ë¶€_í†µì‹ ë¹„ì´ìš©ê¸ˆì•¡\", 0)\n",
    "    fuel = df.get(\"êµí†µ_ì£¼ìœ ì´ìš©ê¸ˆì•¡\", 0)\n",
    "    df[\"v4_lifestyle_auto_payment_flag\"] = (\n",
    "        (comm == 0) & (fuel == 0)\n",
    "    ).astype(\"int8\")\n",
    "\n",
    "    # â‘¬ v4_arrears_recent_flag\n",
    "    arrears_recent = df.get(\"ì—°ì²´ì¼ìˆ˜_ìµœê·¼\", 0)\n",
    "    df[\"v4_arrears_recent_flag\"] = (\n",
    "        arrears_recent > 30\n",
    "    ).astype(\"int8\")\n",
    "\n",
    "    # â‘­ v4_cardloan_cleanup_flag\n",
    "    loan_used       = df.get(\"ì¹´ë“œë¡ ì´ìš©ê¸ˆì•¡_ëˆ„ì \", 0)\n",
    "    loan_balance_b0 = df.get(\"ì”ì•¡_ì¹´ë“œë¡ _B0M\", 0)\n",
    "    loan_last_gap   = (TODAY - df[\"ìµœì¢…ì´ìš©ì¼ì_ì¹´ë“œë¡ _dt\"]).dt.days\n",
    "\n",
    "    cond_used            = loan_used > 1_000_000\n",
    "    cond_zero_balance    = loan_balance_b0 == 0\n",
    "    cond_long_since_loan = loan_last_gap > 365\n",
    "\n",
    "    df[\"v4_cardloan_cleanup_flag\"] = (\n",
    "        cond_used & cond_zero_balance & cond_long_since_loan\n",
    "    ).astype(\"int8\")\n",
    "\n",
    "    # â‘® v4_online_offline_usage_ratio_R6M\n",
    "    online_6m  = df.get(\"ì´ìš©ê¸ˆì•¡_ì˜¨ë¼ì¸_R6M\", 0)\n",
    "    offline_6m = df.get(\"ì´ìš©ê¸ˆì•¡_ì˜¤í”„ë¼ì¸_R6M\", 0)\n",
    "    df[\"v4_online_offline_usage_ratio_R6M\"] = (\n",
    "        online_6m / (online_6m + offline_6m + EPS)\n",
    "    )\n",
    "\n",
    "    # ë‚ ì§œ ë„ì›€ ì»¬ëŸ¼ ì •ë¦¬\n",
    "    drop_cols = [c for c in df.columns if c.endswith(\"_dt\")]\n",
    "    df.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# --------------------------------\n",
    "# 2) train/test v4 ë§Œë“¤ê¸°\n",
    "# --------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) v1 train/test ë¡œë“œ (ì›ë³¸ ë°ì´í„° ë””ë ‰í† ë¦¬ì—ì„œ)\n",
    "    train_v1_path = ORIGINAL_DATA_DIR / \"preprocessed\" / \"df_master_preprocessed_v1_train.parquet\"\n",
    "    test_v1_path  = ORIGINAL_DATA_DIR / \"preprocessed\" / \"df_master_preprocessed_v1_test.parquet\"\n",
    "\n",
    "    train_v1 = pd.read_parquet(train_v1_path)\n",
    "    test_v1  = pd.read_parquet(test_v1_path)\n",
    "\n",
    "    print(\"\\n[Loaded v1 train]\", train_v1.shape)\n",
    "    print(\"[Loaded v1 test ]\", test_v1.shape)\n",
    "\n",
    "    # 2) v3.5 + v4 FE (train)\n",
    "    print(\"\\n=== v3.5 + v4 FE (train) ===\")\n",
    "    train_v35, v35_features = add_v35_features(train_v1, FEAT_DIR)\n",
    "    train_v4 = add_v4_features(train_v35)\n",
    "    print(\"[train_v4 shape]:\", train_v4.shape)\n",
    "\n",
    "    # 3) v3.5 + v4 FE (test)\n",
    "    print(\"\\n=== v3.5 + v4 FE (test) ===\")\n",
    "    test_v35, _ = add_v35_features(test_v1, FEAT_DIR)\n",
    "    test_v4 = add_v4_features(test_v35)\n",
    "    print(\"[test_v4 shape]:\", test_v4.shape)\n",
    "\n",
    "    # 4) v4_feature_list.csv ê¸°ì¤€ìœ¼ë¡œ ì»¬ëŸ¼ ì •ë ¬/ì„ íƒ (train ê¸°ì¤€)\n",
    "    v4_feat_path = FEAT_DIR / \"v4_feature_list.csv\"\n",
    "    if v4_feat_path.exists():\n",
    "        v4_list = pd.read_csv(v4_feat_path)\n",
    "        v4_feature_names = v4_list[\"feature\"].tolist()\n",
    "        print(\"\\n[v4_feature_list ê°œìˆ˜]:\", len(v4_feature_names))\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"{v4_feat_path}ê°€ ì—†ìŠµë‹ˆë‹¤. features í´ë” í™•ì¸ í•„ìš”\")\n",
    "\n",
    "    # --- train: Segment + v4_feature_names ---\n",
    "    if \"Segment\" not in train_v4.columns:\n",
    "        raise KeyError(\"train_v4ì— Segment ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. v1 ì „ì²˜ë¦¬ì—ì„œ Segmentê°€ ë“œëë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸ í•„ìš”.\")\n",
    "\n",
    "    final_cols_train = [\"Segment\"] + [f for f in v4_feature_names if f in train_v4.columns]\n",
    "    missing_train = [f for f in v4_feature_names if f not in train_v4.columns]\n",
    "\n",
    "    print(\"\\n[train] ìµœì¢… ì‚¬ìš© feature ìˆ˜:\", len(final_cols_train)-1, \"(+Segment)\")\n",
    "    print(\"[train] v4_list ê¸°ì¤€ ëˆ„ë½ feature ìˆ˜:\", len(missing_train))\n",
    "    if missing_train:\n",
    "        print(\"ëˆ„ë½ ì˜ˆì‹œ:\", missing_train[:20])\n",
    "\n",
    "    df_master_v4_train = train_v4[final_cols_train].copy()\n",
    "    print(\"[df_master_v4_train shape]:\", df_master_v4_train.shape)\n",
    "\n",
    "    # --- test: Segment ì—†ì´, trainê³¼ ë™ì¼ featureë§Œ ì‚¬ìš© ---\n",
    "    final_cols_test = [f for f in v4_feature_names if f in test_v4.columns]\n",
    "    missing_test = [f for f in v4_feature_names if f not in test_v4.columns]\n",
    "\n",
    "    print(\"\\n[test] ìµœì¢… ì‚¬ìš© feature ìˆ˜:\", len(final_cols_test))\n",
    "    print(\"[test] v4_list ê¸°ì¤€ ëˆ„ë½ feature ìˆ˜:\", len(missing_test))\n",
    "    if missing_test:\n",
    "        print(\"ëˆ„ë½ ì˜ˆì‹œ:\", missing_test[:20])\n",
    "\n",
    "    df_master_v4_test = test_v4[final_cols_test].copy()\n",
    "    print(\"[df_master_v4_test shape]:\", df_master_v4_test.shape)\n",
    "\n",
    "    # 5) ì €ì¥ (final_submission/data í´ë”ì—)\n",
    "    out_train = DATA_DIR / \"df_master_v4_train.parquet\"\n",
    "    out_test  = DATA_DIR / \"df_master_v4_test.parquet\"\n",
    "\n",
    "    df_master_v4_train.to_parquet(out_train)\n",
    "    df_master_v4_test.to_parquet(out_test)\n",
    "\n",
    "    print(\"\\nâœ… Saved v4:\")\n",
    "    print(\" -\", out_train)\n",
    "    print(\" -\", out_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9005f0d7-637b-4a73-a3a9-09e2b31c8794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:credit_project]",
   "language": "python",
   "name": "conda-env-credit_project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
