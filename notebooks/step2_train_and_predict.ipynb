{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e471987",
   "metadata": {},
   "source": [
    "# Step 2: ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡\n",
    "\n",
    "## ğŸ“Œ ëª©ì \n",
    "Step 1ì—ì„œ ìƒì„±í•œ v4 ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ 2ë‹¨ê³„ ê³„ì¸µì  ë¶„ë¥˜ ëª¨ë¸ì„ í•™ìŠµí•˜ê³ , í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ğŸ”„ í”„ë¡œì„¸ìŠ¤\n",
    "1. **ë°ì´í„° ë¡œë“œ**: v4 train/test ë°ì´í„°\n",
    "2. **Stage 1 í•™ìŠµ**: Rare(0,1) vs Others(2,3,4) ì´ì§„ ë¶„ë¥˜ + Threshold íŠœë‹\n",
    "3. **Stage 2A í•™ìŠµ**: Rare ë‚´ë¶€ Segment 0 vs 1 ë¶„ë¥˜\n",
    "4. **Stage 2B í•™ìŠµ**: Others ë‚´ë¶€ Segment 2 vs 3 vs 4 ë¶„ë¥˜\n",
    "5. **íŒŒì´í”„ë¼ì¸ êµ¬ì„±**: ì „ì²´ ì˜ˆì¸¡ í•¨ìˆ˜ ì •ì˜\n",
    "6. **Test ì˜ˆì¸¡**: ìµœì¢… ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "\n",
    "## ğŸ“Š ì¶œë ¥ë¬¼\n",
    "- `models/model_stage1_rare_vs_others.pkl`: Stage1 ëª¨ë¸\n",
    "- `models/model_stage2A_seg01.pkl`: Stage2A ëª¨ë¸\n",
    "- `models/model_stage2B_seg234.pkl`: Stage2B ëª¨ë¸\n",
    "- `models/label_encoder_234.pkl`: Segment 2/3/4 ì¸ì½”ë”\n",
    "- `results/v4_test_predictions.csv`: **ìµœì¢… ì œì¶œ íŒŒì¼**\n",
    "- `results/v4_test_predictions.parquet`: ìµœì¢… ì œì¶œ íŒŒì¼ (Parquet)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3ff78c",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ ì½”ë“œ ì‹¤í–‰\n",
    "\n",
    "ì•„ë˜ ì…€ì„ ì‹¤í–‰í•˜ë©´ ì „ì²´ íŒŒì´í”„ë¼ì¸ì´ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤:\n",
    "1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "2. Stage 1, 2A, 2B ëª¨ë¸ í•™ìŠµ\n",
    "3. Validation í‰ê°€\n",
    "4. Test ì˜ˆì¸¡ ë° ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "\n",
    "**ì˜ˆìƒ ì‹¤í–‰ ì‹œê°„**: ì•½ 10-20ë¶„ (ë°ì´í„° í¬ê¸°ì™€ CPU ì„±ëŠ¥ì— ë”°ë¼ ë‹¤ë¦„)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bdfe05-04d7-449e-adc1-b334b3ccef7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: C:\\Users\\User\\ì „ì‚°í†µê³„í”„ë¡œì íŠ¸\n",
      "DATA_DIR   : C:\\Users\\User\\ì „ì‚°í†µê³„í”„ë¡œì íŠ¸\\data\n",
      "\n",
      "[df_train shape]: (400000, 166)\n",
      "[df_test  shape]: (100000, 165)\n",
      "train columns ì˜ˆì‹œ: ['Segment', 'ì´ìš©ê°œì›”ìˆ˜_ê²°ì œì¼_R6M', 'í‰ì”_ì¼ì‹œë¶ˆ_6M', 'v4_limit_to_usage_ratio_R12M', 'ì´ìš©ê±´ìˆ˜_ì²´í¬_R12M', 'ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_R3M', 'v4_balance_to_usage_ratio', 'ì†Œì§€ì¹´ë“œìˆ˜_ìœ íš¨_ì‹ ìš©', 'ì”ì•¡_ì‹ íŒcaìµœëŒ€í•œë„ì†Œì§„ìœ¨_r6m', 'ì›”ì¤‘í‰ì”_ì¼ì‹œë¶ˆ']\n",
      "\n",
      "[FEATURE_COLS ê°œìˆ˜]: 165\n",
      "FEATURE_COLS ì˜ˆì‹œ: ['ì´ìš©ê°œì›”ìˆ˜_ê²°ì œì¼_R6M', 'í‰ì”_ì¼ì‹œë¶ˆ_6M', 'v4_limit_to_usage_ratio_R12M', 'ì´ìš©ê±´ìˆ˜_ì²´í¬_R12M', 'ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_R3M', 'v4_balance_to_usage_ratio', 'ì†Œì§€ì¹´ë“œìˆ˜_ìœ íš¨_ì‹ ìš©', 'ì”ì•¡_ì‹ íŒcaìµœëŒ€í•œë„ì†Œì§„ìœ¨_r6m', 'ì›”ì¤‘í‰ì”_ì¼ì‹œë¶ˆ', 'í•œë„ì¦ì•¡í›„ê²½ê³¼ì›”']\n",
      "\n",
      "[Stage1 Train/Val]\n",
      "Train shape: (320000, 165)  / rare ë¹„ìœ¨: 0.000465625\n",
      "Val   shape: (80000, 165)  / rare ë¹„ìœ¨: 0.0004625\n",
      "\n",
      "[Stage1 scale_pos_weight]: 2146.6510067114095\n",
      "[0]\tvalidation_0-logloss:0.64567\n",
      "[50]\tvalidation_0-logloss:0.05095\n",
      "[100]\tvalidation_0-logloss:0.01170\n",
      "[150]\tvalidation_0-logloss:0.00619\n",
      "[200]\tvalidation_0-logloss:0.00405\n",
      "[250]\tvalidation_0-logloss:0.00297\n",
      "[300]\tvalidation_0-logloss:0.00252\n",
      "[350]\tvalidation_0-logloss:0.00240\n",
      "[400]\tvalidation_0-logloss:0.00235\n",
      "[450]\tvalidation_0-logloss:0.00232\n",
      "[499]\tvalidation_0-logloss:0.00234\n",
      "\n",
      "[Stage1 best threshold(F1 ê¸°ì¤€)]\n",
      "best_thr   : 0.34858462\n",
      "Precision  : 0.32\n",
      "Recall     : 0.43243243243243246\n",
      "F1         : 0.3678160914651869\n",
      "\n",
      "[Stage1 Validation confusion_matrix] (row=true, col=pred)\n",
      "[[79929    34]\n",
      " [   21    16]]\n",
      "ì‹¤ì œ rare ìˆ˜(y=1): 37\n",
      "rareë¡œ ì˜ˆì¸¡ëœ ìˆ˜(pred=1): 50\n",
      "â†’ Recall(rare): 0.4324\n",
      "â†’ Precision(rare): 0.3200\n",
      "\n",
      "[Stage2A í’€] (Segment 0/1)\n",
      "shape: (186, 167)\n",
      "Segment ë¶„í¬:\n",
      "Segment\n",
      "0    162\n",
      "1     24\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[Stage2A Train/Val]\n",
      "Train shape: (148, 165)\n",
      "Segment\n",
      "0    129\n",
      "1     19\n",
      "Name: count, dtype: int64\n",
      "Val   shape: (38, 165)\n",
      "Segment\n",
      "0    33\n",
      "1     5\n",
      "Name: count, dtype: int64\n",
      "[0]\tvalidation_0-logloss:0.38133\n",
      "[50]\tvalidation_0-logloss:0.25751\n",
      "[100]\tvalidation_0-logloss:0.26529\n",
      "[150]\tvalidation_0-logloss:0.28747\n",
      "[200]\tvalidation_0-logloss:0.29448\n",
      "[250]\tvalidation_0-logloss:0.29369\n",
      "[299]\tvalidation_0-logloss:0.29310\n",
      "\n",
      "[Stage2A Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94        33\n",
      "           1       0.67      0.40      0.50         5\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.79      0.68      0.72        38\n",
      "weighted avg       0.88      0.89      0.88        38\n",
      "\n",
      "Stage2A Macro F1: 0.7205882352941176\n",
      "\n",
      "[Stage2B í’€] (Segment 2/3/4)\n",
      "shape: (399814, 167)\n",
      "Segment ë¶„í¬:\n",
      "Segment\n",
      "2     21265\n",
      "3     58207\n",
      "4    320342\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[Stage2B Train/Val]\n",
      "Train shape: (319851, 165)\n",
      "Segment\n",
      "2     17012\n",
      "3     46566\n",
      "4    256273\n",
      "Name: count, dtype: int64\n",
      "Val   shape: (79963, 165)\n",
      "Segment\n",
      "2     4253\n",
      "3    11641\n",
      "4    64069\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[Stage2B class_weights]\n",
      "  class 0 (ì›ë˜ Segment 2): 6.267\n",
      "  class 1 (ì›ë˜ Segment 3): 2.290\n",
      "  class 2 (ì›ë˜ Segment 4): 0.416\n",
      "[0]\tvalidation_0-mlogloss:1.05587\n",
      "[50]\tvalidation_0-mlogloss:0.44731\n",
      "[100]\tvalidation_0-mlogloss:0.37605\n",
      "[150]\tvalidation_0-mlogloss:0.34938\n",
      "[200]\tvalidation_0-mlogloss:0.33239\n",
      "[250]\tvalidation_0-mlogloss:0.31993\n",
      "[300]\tvalidation_0-mlogloss:0.30920\n",
      "[350]\tvalidation_0-mlogloss:0.30081\n",
      "[400]\tvalidation_0-mlogloss:0.29357\n",
      "[450]\tvalidation_0-mlogloss:0.28743\n",
      "[500]\tvalidation_0-mlogloss:0.28196\n",
      "[550]\tvalidation_0-mlogloss:0.27742\n",
      "[600]\tvalidation_0-mlogloss:0.27289\n",
      "[650]\tvalidation_0-mlogloss:0.26869\n",
      "[699]\tvalidation_0-mlogloss:0.26516\n",
      "\n",
      "[Stage2B Classification Report (ì›ë˜ Segment ê¸°ì¤€)]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.66      0.76      0.71      4253\n",
      "           3       0.63      0.80      0.71     11641\n",
      "           4       0.98      0.92      0.95     64069\n",
      "\n",
      "    accuracy                           0.90     79963\n",
      "   macro avg       0.76      0.83      0.79     79963\n",
      "weighted avg       0.91      0.90      0.90     79963\n",
      "\n",
      "Stage2B Macro F1: 0.7881930531077493\n",
      "\n",
      "[Val Segment ë¶„í¬ (ì›ë˜ 0~4)]\n",
      "Segment\n",
      "0       30\n",
      "1        7\n",
      "2     4226\n",
      "3    11605\n",
      "4    64132\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[Stage1+Stage2A+Stage2B v4 ìµœì¢… Classification Report (Val)]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.43      0.36        30\n",
      "           1       0.43      0.43      0.43         7\n",
      "           2       0.82      0.95      0.88      4226\n",
      "           3       0.73      0.91      0.81     11605\n",
      "           4       0.99      0.94      0.96     64132\n",
      "\n",
      "    accuracy                           0.93     80000\n",
      "   macro avg       0.65      0.73      0.69     80000\n",
      "weighted avg       0.94      0.93      0.94     80000\n",
      "\n",
      "Macro F1 (v4 ì „ì²´ íŒŒì´í”„ë¼ì¸, Val): 0.6877255781918972\n",
      "\n",
      "=== v4 íŒŒì´í”„ë¼ì¸ì„ testì— ì ìš© ===\n",
      "[df_test shape]: (100000, 165)\n",
      "test ì˜ˆì¸¡ê°’ ë¶„í¬ (0~4):\n",
      "0       48\n",
      "1        1\n",
      "2     5783\n",
      "3    17689\n",
      "4    76479\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[test_íšŒì›ì •ë³´ shape]: (100000, 77)\n",
      "\n",
      "[submission head]\n",
      "             ID  Segment_pred Segment_pred_label\n",
      "0  TRAIN_023218             2                  C\n",
      "1  TRAIN_020731             3                  D\n",
      "2  TRAIN_039555             4                  E\n",
      "3  TRAIN_147506             4                  E\n",
      "4  TRAIN_314215             3                  D\n",
      "\n",
      "âœ… Saved predictions:\n",
      " - C:\\Users\\User\\ì „ì‚°í†µê³„í”„ë¡œì íŠ¸\\data\\v4_test_predictions.parquet\n",
      " - C:\\Users\\User\\ì „ì‚°í†µê³„í”„ë¡œì íŠ¸\\data\\v4_test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# =========================================\n",
    "# 0) ê²½ë¡œ / ë°ì´í„° ë¡œë“œ\n",
    "# =========================================\n",
    "PROJECT_ROOT = Path(r\"C:\\Users\\User\\ì „ì‚°í†µê³„í”„ë¡œì íŠ¸\\final_submission\")\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
    "\n",
    "# ì›ë³¸ ë°ì´í„° ê²½ë¡œ (test ID ì¡°íšŒìš©)\n",
    "ORIGINAL_DATA_DIR = Path(r\"C:\\Users\\User\\ì „ì‚°í†µê³„í”„ë¡œì íŠ¸\\data\")\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"DATA_DIR   :\", DATA_DIR)\n",
    "print(\"MODELS_DIR :\", MODELS_DIR)\n",
    "print(\"RESULTS_DIR:\", RESULTS_DIR)\n",
    "\n",
    "train_path = DATA_DIR / \"df_master_v4_train.parquet\"\n",
    "test_path  = DATA_DIR / \"df_master_v4_test.parquet\"\n",
    "\n",
    "df_train = pd.read_parquet(train_path)\n",
    "df_test  = pd.read_parquet(test_path)\n",
    "\n",
    "print(\"\\n[df_train shape]:\", df_train.shape)\n",
    "print(\"[df_test  shape]:\", df_test.shape)\n",
    "print(\"train columns ì˜ˆì‹œ:\", df_train.columns[:10].tolist())\n",
    "\n",
    "# =========================================\n",
    "# 1) rare_flag ìƒì„± + FEATURE_COLS ì •ì˜\n",
    "# =========================================\n",
    "# Segment: 0/1 â†’ rare, 2/3/4 â†’ ì¼ë°˜\n",
    "df_train[\"rare_flag\"] = df_train[\"Segment\"].isin([0, 1]).astype(\"int8\")\n",
    "\n",
    "FEATURE_COLS = [c for c in df_train.columns if c not in [\"Segment\", \"rare_flag\"]]\n",
    "\n",
    "print(\"\\n[FEATURE_COLS ê°œìˆ˜]:\", len(FEATURE_COLS))\n",
    "print(\"FEATURE_COLS ì˜ˆì‹œ:\", FEATURE_COLS[:10])\n",
    "\n",
    "# =========================================\n",
    "# 2) Stage1: rare_flag (0/1) ì´ì§„ ë¶„ë¥˜\n",
    "# =========================================\n",
    "X_stage1 = df_train[FEATURE_COLS]\n",
    "y_stage1 = df_train[\"rare_flag\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_stage1,\n",
    "    y_stage1,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_stage1\n",
    ")\n",
    "\n",
    "print(\"\\n[Stage1 Train/Val]\")\n",
    "print(\"Train shape:\", X_train.shape, \" / rare ë¹„ìœ¨:\", y_train.mean())\n",
    "print(\"Val   shape:\", X_val.shape, \" / rare ë¹„ìœ¨:\", y_val.mean())\n",
    "\n",
    "scale_pos_weight = (1 - y_train.mean()) / y_train.mean()\n",
    "print(\"\\n[Stage1 scale_pos_weight]:\", scale_pos_weight)\n",
    "\n",
    "model_stage1 = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=500,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    min_child_weight=1,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "model_stage1.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "# --- threshold íŠœë‹ (F1 ìµœëŒ“ê°’ ê¸°ì¤€) ---\n",
    "val_prob = model_stage1.predict_proba(X_val)[:, 1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, val_prob)\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-9)\n",
    "\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_thr = thresholds[best_idx]\n",
    "\n",
    "print(\"\\n[Stage1 best threshold(F1 ê¸°ì¤€)]\")\n",
    "print(\"best_thr   :\", best_thr)\n",
    "print(\"Precision  :\", precision[best_idx])\n",
    "print(\"Recall     :\", recall[best_idx])\n",
    "print(\"F1         :\", f1_scores[best_idx])\n",
    "\n",
    "# confusion matrix\n",
    "val_pred_bin = (val_prob >= best_thr).astype(int)\n",
    "cm = confusion_matrix(y_val, val_pred_bin, labels=[0, 1])\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(\"\\n[Stage1 Validation confusion_matrix] (row=true, col=pred)\")\n",
    "print(cm)\n",
    "print(\"ì‹¤ì œ rare ìˆ˜(y=1):\", y_val.sum())\n",
    "print(\"rareë¡œ ì˜ˆì¸¡ëœ ìˆ˜(pred=1):\", val_pred_bin.sum())\n",
    "\n",
    "recall_rare = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "precision_rare = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "print(f\"â†’ Recall(rare): {recall_rare:.4f}\")\n",
    "print(f\"â†’ Precision(rare): {precision_rare:.4f}\")\n",
    "\n",
    "# =========================================\n",
    "# 3) Stage2A: Segment 0/1 ë¶„ë¥˜ (í¬ê·€ ë‚´ë¶€)\n",
    "# =========================================\n",
    "stage2A_df = df_train[df_train[\"Segment\"].isin([0, 1])].copy()\n",
    "X_stage2A = stage2A_df[FEATURE_COLS]\n",
    "y_stage2A = stage2A_df[\"Segment\"]\n",
    "\n",
    "print(\"\\n[Stage2A í’€] (Segment 0/1)\")\n",
    "print(\"shape:\", stage2A_df.shape)\n",
    "print(\"Segment ë¶„í¬:\")\n",
    "print(y_stage2A.value_counts().sort_index())\n",
    "\n",
    "X_A_train, X_A_val, y_A_train, y_A_val = train_test_split(\n",
    "    X_stage2A, y_stage2A,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_stage2A\n",
    ")\n",
    "\n",
    "print(\"\\n[Stage2A Train/Val]\")\n",
    "print(\"Train shape:\", X_A_train.shape)\n",
    "print(y_A_train.value_counts().sort_index())\n",
    "print(\"Val   shape:\", X_A_val.shape)\n",
    "print(y_A_val.value_counts().sort_index())\n",
    "\n",
    "clf_A = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=300,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "clf_A.fit(\n",
    "    X_A_train, y_A_train,\n",
    "    eval_set=[(X_A_val, y_A_val)],\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "y_A_pred = clf_A.predict(X_A_val)\n",
    "print(\"\\n[Stage2A Classification Report]\")\n",
    "print(classification_report(y_A_val, y_A_pred))\n",
    "print(\"Stage2A Macro F1:\", f1_score(y_A_val, y_A_pred, average=\"macro\"))\n",
    "\n",
    "# =========================================\n",
    "# 4) Stage2B: Segment 2/3/4 ë¶„ë¥˜ (ì¼ë°˜ ë‚´ë¶€)\n",
    "# =========================================\n",
    "stage2B_df = df_train[df_train[\"Segment\"].isin([2, 3, 4])].copy()\n",
    "X_stage2B = stage2B_df[FEATURE_COLS]\n",
    "y_stage2B = stage2B_df[\"Segment\"]\n",
    "\n",
    "print(\"\\n[Stage2B í’€] (Segment 2/3/4)\")\n",
    "print(\"shape:\", stage2B_df.shape)\n",
    "print(\"Segment ë¶„í¬:\")\n",
    "print(y_stage2B.value_counts().sort_index())\n",
    "\n",
    "X_B_train, X_B_val, y_B_train, y_B_val = train_test_split(\n",
    "    X_stage2B, y_stage2B,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_stage2B\n",
    ")\n",
    "\n",
    "print(\"\\n[Stage2B Train/Val]\")\n",
    "print(\"Train shape:\", X_B_train.shape)\n",
    "print(y_B_train.value_counts().sort_index())\n",
    "print(\"Val   shape:\", X_B_val.shape)\n",
    "print(y_B_val.value_counts().sort_index())\n",
    "\n",
    "# 2/3/4 â†’ 0/1/2 ì¸ì½”ë”©\n",
    "le_234 = LabelEncoder()\n",
    "y_B_train_enc = le_234.fit_transform(y_B_train)\n",
    "y_B_val_enc   = le_234.transform(y_B_val)\n",
    "\n",
    "# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ (ë¶ˆê· í˜• ë³´ì •)\n",
    "classes_B = np.unique(y_B_train_enc)\n",
    "class_weights_B = {\n",
    "    c: (len(y_B_train_enc) / (len(classes_B) * (y_B_train_enc == c).sum()))\n",
    "    for c in classes_B\n",
    "}\n",
    "print(\"\\n[Stage2B class_weights]\")\n",
    "for k, v in class_weights_B.items():\n",
    "    print(f\"  class {k} (ì›ë˜ Segment {le_234.inverse_transform([k])[0]}): {v:.3f}\")\n",
    "\n",
    "sample_weight_B = pd.Series(y_B_train_enc).map(class_weights_B).values\n",
    "\n",
    "clf_B = XGBClassifier(\n",
    "    objective=\"multi:softprob\",\n",
    "    max_depth=7,\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=700,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    min_child_weight=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "clf_B.fit(\n",
    "    X_B_train, y_B_train_enc,\n",
    "    sample_weight=sample_weight_B,\n",
    "    eval_set=[(X_B_val, y_B_val_enc)],\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "y_B_pred_enc = clf_B.predict(X_B_val)\n",
    "y_B_pred = le_234.inverse_transform(y_B_pred_enc)\n",
    "\n",
    "print(\"\\n[Stage2B Classification Report (ì›ë˜ Segment ê¸°ì¤€)]\")\n",
    "print(classification_report(y_B_val, y_B_pred))\n",
    "print(\"Stage2B Macro F1:\", f1_score(y_B_val, y_B_pred, average=\"macro\"))\n",
    "\n",
    "# =========================================\n",
    "# 5) ì „ì²´ íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ ì •ì˜\n",
    "# =========================================\n",
    "def predict_v4_pipeline(X_input: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    X_input: Segment/rare_flag ì—†ëŠ” feature DataFrame\n",
    "             (ì»¬ëŸ¼ = FEATURE_COLS ê·¸ëŒ€ë¡œ)\n",
    "    \"\"\"\n",
    "    # 1) ì»¬ëŸ¼ ê°•ì œ ì •ë ¬\n",
    "    X = X_input[FEATURE_COLS].copy()\n",
    "\n",
    "    n_samples = X.shape[0]\n",
    "    y_final = np.full(n_samples, fill_value=-1, dtype=int)\n",
    "\n",
    "    # -------------------------\n",
    "    # 1ë‹¨ê³„: rare vs others\n",
    "    # -------------------------\n",
    "    prob_stage1 = model_stage1.predict_proba(X)[:, 1]\n",
    "    y_pred_rareflag = (prob_stage1 >= best_thr).astype(int)\n",
    "\n",
    "    rare_mask   = (y_pred_rareflag == 1)   # â†’ 0/1\n",
    "    others_mask = (y_pred_rareflag == 0)   # â†’ 2/3/4\n",
    "\n",
    "    # -------------------------\n",
    "    # 2ë‹¨ê³„ A: rare ë‚´ë¶€ (0 vs 1)\n",
    "    # -------------------------\n",
    "    if rare_mask.sum() > 0:\n",
    "        X_rare = X.loc[rare_mask]\n",
    "        y_rare_pred = clf_A.predict(X_rare)   # 0/1\n",
    "        y_final[rare_mask] = y_rare_pred\n",
    "\n",
    "    # -------------------------\n",
    "    # 2ë‹¨ê³„ B: others ë‚´ë¶€ (2/3/4)\n",
    "    # -------------------------\n",
    "    if others_mask.sum() > 0:\n",
    "        X_others = X.loc[others_mask]\n",
    "        y_others_pred_enc = clf_B.predict(X_others)           # 0/1/2\n",
    "        y_others_pred = le_234.inverse_transform(y_others_pred_enc)  # 2/3/4\n",
    "        y_final[others_mask] = y_others_pred\n",
    "\n",
    "    if (y_final == -1).any():\n",
    "        raise ValueError(\"y_finalì— -1(ë¯¸í• ë‹¹) ê°’ì´ ìˆìŠµë‹ˆë‹¤. ë§ˆìŠ¤í¬/ì¸ë±ìŠ¤ í™•ì¸ í•„ìš”.\")\n",
    "\n",
    "    return y_final\n",
    "\n",
    "# =========================================\n",
    "# 6) train ë‚´ë¶€ Validationì—ì„œ v4 ì „ì²´ í‰ê°€\n",
    "# =========================================\n",
    "val_index = X_val.index  # Stage1ì—ì„œ ë‚˜ëˆˆ validation index\n",
    "\n",
    "X_val_full = df_train.loc[val_index, FEATURE_COLS]\n",
    "y_val_segment = df_train.loc[val_index, \"Segment\"]\n",
    "\n",
    "print(\"\\n[Val Segment ë¶„í¬ (ì›ë˜ 0~4)]\")\n",
    "print(y_val_segment.value_counts().sort_index())\n",
    "\n",
    "y_pred_v4 = predict_v4_pipeline(X_val_full)\n",
    "\n",
    "print(\"\\n[Stage1+Stage2A+Stage2B v4 ìµœì¢… Classification Report (Val)]\")\n",
    "print(classification_report(y_val_segment, y_pred_v4))\n",
    "\n",
    "macro_f1_v4 = f1_score(y_val_segment, y_pred_v4, average=\"macro\")\n",
    "print(\"Macro F1 (v4 ì „ì²´ íŒŒì´í”„ë¼ì¸, Val):\", macro_f1_v4)\n",
    "\n",
    "# =========================================\n",
    "# 7) test ë°ì´í„°ì— ìµœì¢… íŒŒì´í”„ë¼ì¸ ì ìš©\n",
    "# =========================================\n",
    "print(\"\\n=== v4 íŒŒì´í”„ë¼ì¸ì„ testì— ì ìš© ===\")\n",
    "print(\"[df_test shape]:\", df_test.shape)\n",
    "\n",
    "X_test_full = df_test[FEATURE_COLS]\n",
    "y_test_pred = predict_v4_pipeline(X_test_full)   # 0~4\n",
    "\n",
    "print(\"test ì˜ˆì¸¡ê°’ ë¶„í¬ (0~4):\")\n",
    "print(pd.Series(y_test_pred).value_counts().sort_index())\n",
    "\n",
    "# ì›ë˜ ë ˆì´ë¸”(A~E)ë¡œë„ ë§Œë“¤ì–´ë‘ê¸°\n",
    "seg_map = {0: \"A\", 1: \"B\", 2: \"C\", 3: \"D\", 4: \"E\"}\n",
    "y_test_pred_label = pd.Series(y_test_pred).map(seg_map)\n",
    "\n",
    "# test ID ë¶™ì´ê¸° (íšŒì›ì •ë³´ì˜ ID ì‚¬ìš©)\n",
    "test_member_path = DATA_DIR / \"1.á„’á…¬á„‹á…¯á†«á„Œá…¥á†¼á„‡á…©\" / \"test_á„’á…¬á„‹á…¯á†«á„Œá…¥á†¼á„‡á…©.parquet\"\n",
    "df_test_member = pd.read_parquet(test_member_path)\n",
    "\n",
    "print(\"\\n[test_íšŒì›ì •ë³´ shape]:\", df_test_member.shape)\n",
    "\n",
    "assert len(df_test_member) == len(df_test), \"test ê¸¸ì´ ì•ˆ ë§ìŒ. v1 ì „ì²˜ë¦¬ ìˆœì„œ í™•ì¸ í•„ìš”.\"\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": df_test_member[\"ID\"].values,\n",
    "    \"Segment_pred\": y_test_pred,\n",
    "    \"Segment_pred_label\": y_test_pred_label.values\n",
    "})\n",
    "\n",
    "print(\"\\n[submission head]\")\n",
    "print(submission.head())\n",
    "\n",
    "out_parquet = DATA_DIR / \"v4_test_predictions.parquet\"\n",
    "out_csv     = DATA_DIR / \"v4_test_predictions.csv\"\n",
    "\n",
    "submission.to_parquet(out_parquet, index=False)\n",
    "submission.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"\\nâœ… Saved predictions:\")\n",
    "print(\" -\", out_parquet)\n",
    "print(\" -\", out_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb786c9-cabe-4368-8030-7a234a33a199",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:credit_project]",
   "language": "python",
   "name": "conda-env-credit_project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
