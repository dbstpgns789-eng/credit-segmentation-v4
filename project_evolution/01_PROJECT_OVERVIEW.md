# 01. 프로젝트 전체 개요

## 🎯 프로젝트 목표

**신용카드 고객 데이터를 기반으로 5개 세그먼트(A~E)로 고객을 분류하여, 맞춤형 마케팅 및 리스크 관리 전략 수립**

---

## 📊 데이터 개요

### 원천 데이터 (8개 카테고리)

| 카테고리 | 파일명 | 주요 정보 | 변수 수 |
|---------|--------|----------|--------|
| 1️⃣ 회원정보 | 회원정보.parquet | 고객 기본 정보, 가입일, 나이, 성별 등 | ~20개 |
| 2️⃣ 신용정보 | 신용정보.parquet | 신용등급, 연체 이력, 한도 정보 | ~30개 |
| 3️⃣ 승인매출정보 | 승인매출정보.parquet | 카드 사용 내역, 업종별 사용액 | ~50개 |
| 4️⃣ 청구입금정보 | 청구정보.parquet | 청구금액, 입금액, 결제 패턴 | ~25개 |
| 5️⃣ 잔액정보 | 잔액정보.parquet | 월별 잔액, 한도 소진율 | ~20개 |
| 6️⃣ 채널정보 | 채널정보.parquet | 온/오프라인 사용 패턴 | ~15개 |
| 7️⃣ 마케팅정보 | 마케팅정보.parquet | 캠페인 반응, 혜택 사용 | ~20개 |
| 8️⃣ 성과정보 | 성과정보.parquet | **타겟 변수 (Segment 0~4)** | ~5개 |

**총 변수 수**: 약 185개 (원천 데이터)

---

## 🎲 타겟 변수: Segment (5개 클래스)

| Segment | 레이블 | 특징 | 비율 (Train) | 샘플 수 |
|---------|-------|------|------------|---------|
| **0** | A | 최상위 고객 (초희귀) | 0.04% | ~162명 |
| **1** | B | 상위 고객 (희귀) | 0.006% | ~24명 |
| **2** | C | 중상위 고객 | 5.3% | ~21,265명 |
| **3** | D | 중위 고객 | 14.6% | ~58,207명 |
| **4** | E | 일반 고객 (다수) | 80.1% | ~320,342명 |

**총 학습 데이터**: 400,000명  
**총 테스트 데이터**: 100,000명

### 🚨 핵심 과제: 극심한 클래스 불균형
- Segment 0/1 (희귀): 전체의 **0.046%** (186명)
- Segment 4 (다수): 전체의 **80.1%** (320,342명)
- **불균형 비율**: 약 **1:1,700**

---

## 🗓️ 프로젝트 타임라인

```
📅 Week 1: 데이터 이해 및 전처리
├─ 8개 원천 데이터 탐색
├─ 결측치/이상치 처리
└─ v1 전처리 파이프라인 구축
    → 산출물: df_master_preprocessed_v1.parquet (185개 변수)

📅 Week 2: v1 베이스라인 모델
├─ XGBoost 기본 설정
├─ Train/Test 분할 (80:20)
└─ 성능 평가
    → Macro F1: ~0.45 (Segment 0,1 탐지 실패)

📅 Week 3: v2 클래스 불균형 대응
├─ sklearn.compute_class_weight 적용
├─ sample_weight 기반 학습
└─ 성능 개선
    → Macro F1: ~0.52 (+15% 향상)

📅 Week 4: v3 피처 선택 (Top50)
├─ 상관분석 + 모델 중요도 + 도메인 지식
├─ 185개 → 50개 피처 선택
└─ 과적합 감소
    → Macro F1: ~0.58 (+12% 향상)

📅 Week 5: v3.5 하이브리드 피처
├─ Top50 → Top150 확장
├─ 도메인 파생변수 6개 추가
└─ 성능 안정화
    → Macro F1: ~0.62 (+7% 향상)

📅 Week 6-7: v4 희귀 세그먼트 특화
├─ 2단계 계층적 분류 전략
├─ 희귀 세그먼트 전용 피처 15개 추가
├─ Threshold 튜닝 + Focal Loss 실험
└─ 최종 모델
    → Macro F1: 0.688 (+11% 향상, 최종)
```

---

## 🔄 버전별 주요 변화 요약

### v1: 기본 베이스라인
- **전략**: 모든 원천 변수 사용 + XGBoost 기본 설정
- **문제점**: 희귀 클래스 탐지 실패, 과적합
- **Macro F1**: 0.45

### v2: 클래스 가중치 적용
- **전략**: `compute_class_weight("balanced")` 사용
- **개선**: 희귀 클래스 recall 소폭 증가
- **Macro F1**: 0.521 (+16%)

### v3: 피처 선택 (Top50)
- **전략**: 상관분석 + 모델 중요도 + 도메인 지식
- **문제**: 피처를 너무 적게 선택하여 성능 하락
- **Macro F1**: 0.492 (-6%)

### v3.5: 하이브리드 Top150 + 도메인 FE
- **전략**: Top50 → Top150 + 도메인 파생변수 6개
- **개선**: v3 대비 성능 회복, 안정성 증가
- **Macro F1**: 0.531 (+8%)

### v4: 2단계 분류 + 희귀 특화 피처
- **전략**: 
  - Stage 1: Rare vs Others (이진 분류)
  - Stage 2A: Segment 0 vs 1
  - Stage 2B: Segment 2 vs 3 vs 4
  - 희귀 세그먼트 전용 피처 15개 추가
- **개선**: 희귀 클래스 탐지율 급증
- **Macro F1**: 0.688 (+30%)

---

## 📈 성능 개선 곡선

```
Macro F1 Score
    0.70 |                                    ● v4
         |                              ●
    0.65 |                        ●
         |                  ●
    0.60 |            ●
         |      ●
    0.55 |  ●
         |
    0.50 |●
         |
    0.45 +------------------------------------------
          v1   v2   v3   v3.5  v4
         Base Weight Feat Hybrid Hier
              Select       archical
```

**총 개선율**: +53% (0.45 → 0.688)

---

## 🎯 핵심 성공 요인

### 1. **체계적인 반복 개선**
- 매 버전마다 명확한 가설과 실험 설계
- 정량적 성능 측정 및 비교

### 2. **도메인 지식 활용**
- 금융 데이터 특성 이해
- 비즈니스 로직 기반 파생변수 생성

### 3. **불균형 데이터 전략**
- 클래스 가중치 → 계층적 분류로 진화
- Rare 세그먼트 전용 피처 개발

### 4. **피처 엔지니어링**
- 185개 → 50개 → 150개 → 167개 (v4 최종)
- 양보다 질: 의미 있는 피처 집중 개발

---

## 🔍 남은 과제 및 향후 발전 방향

### v5 아이디어
1. **앙상블 전략**: XGBoost + LightGBM + CatBoost 앙상블
2. **딥러닝 시도**: TabNet, FT-Transformer 등
3. **SMOTE 변형**: ADASYN, BorderlineSMOTE 실험
4. **외부 데이터**: 경제 지표, 업종별 트렌드 결합
5. **시계열 피처**: 월별 추세, 계절성 반영

### 한계점
- Segment 0,1 샘플 수 부족 (186명)
- 과적합 위험 (특히 Stage 2A)
- 계산 비용 증가 (2단계 분류)

---

## 📚 참고 문서

- **데이터 상세**: `02_DATA_UNDERSTANDING.md` - 8개 원천 데이터 분석
- **버전 발전**: `03_VERSION_EVOLUTION.md` - v1~v4 상세 과정 ⭐ 핵심
- **피처 전략**: `04_FEATURE_ENGINEERING_STRATEGY.md` - FE 철학 및 방법론

---

## 📝 문서 정보
**최종 업데이트**: 2025-12-08  
**작성자**: 윤세훈
